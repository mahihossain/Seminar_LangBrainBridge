{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "# ---------------------- Parameters ---------------------- #\n",
    "data_dir = \"data\"\n",
    "text_dir = \"data/text\"\n",
    "fmri_reading_trn = \"data/subject{}_reading_fmri_data_trn.hdf\"\n",
    "fmri_reading_val = \"data/subject{}_reading_fmri_data_val.hdf\"\n",
    "fmri_listening_trn = \"data/subject{}_listening_fmri_data_trn.hdf\"\n",
    "fmri_listening_val = \"data/subject{}_listening_fmri_data_val.hdf\"\n",
    "subjects = [1, 2, 3, 5, 7, 8]  # List of subject numbers \n",
    "\n",
    "# ---------------------- fMRI Data Shapes (From Previous Code) ---------------------- #\n",
    "# ... (Ensure that  data_shapes dictionary populated from  previous code in initial_notebook)\n",
    "\n",
    "# ---------------------- Process Text Data ---------------------- #\n",
    "text_data = {}\n",
    "for filename in os.listdir(text_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        story_name = filename[:-4]  # Remove '.txt' extension\n",
    "        with open(os.path.join(text_dir, filename), 'r') as f:\n",
    "            text_data[story_name] = f.read()\n",
    "\n",
    "# ---------------------- Create DataFrame ---------------------- #\n",
    "all_data = []\n",
    "for subject in subjects:\n",
    "    for story_name, story_text in text_data.items():\n",
    "        for task in ['reading', 'listening']:\n",
    "            for split in ['trn', 'val']:\n",
    "                fmri_filename = eval(f\"fmri_{task}_{split}\")  # Dynamically build filename\n",
    "                fmri_file = fmri_filename.format(subject)\n",
    "\n",
    "                # Check if the corresponding fMRI data exists\n",
    "                if story_name in data_shapes and os.path.isfile(fmri_file):\n",
    "                    fmri_shape = data_shapes[story_name]\n",
    "                    all_data.append({\n",
    "                        'subject': subject,\n",
    "                        'story_name': story_name,\n",
    "                        'text': story_text,\n",
    "                        'task': task,\n",
    "                        'split': split,\n",
    "                        'fmri_shape': fmri_shape\n",
    "                    })\n",
    "\n",
    "# Create the final DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# ---------------------- Save DataFrame ---------------------- #\n",
    "df.to_csv(\"data/df_text.hdf\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import aeneas  # Make sure you have Aeneas installed: pip install aeneas \n",
    "import wave\n",
    "from tqdm import tqdm  # Optional, for progress bar\n",
    "\n",
    "# ---------------------- Parameters ---------------------- #\n",
    "data_dir = \"data\"\n",
    "audio_dir = \"data/audio\"\n",
    "transcripts_dir = \"stimuli\"\n",
    "aligned_audio_dir = \"data/aligned_audio\"\n",
    "fmri_reading_trn = \"data/subject{}_reading_fmri_data_trn.hdf\" # Just keeping these for reference\n",
    "fmri_reading_val = \"data/subject{}_reading_fmri_data_val.hdf\"\n",
    "fmri_listening_trn = \"data/subject{}_listening_fmri_data_trn.hdf\"\n",
    "fmri_listening_val = \"data/subject{}_listening_fmri_data_val.hdf\"\n",
    "subjects = [1, 2, 3, 5, 7, 8] \n",
    "\n",
    "# ---------------------- Load DataFrame ---------------------- #\n",
    "df = pd.read_csv(\"data/df_text.hdf\")\n",
    "\n",
    "# ---------------------- Process Audio Data ---------------------- #\n",
    "for index, row in tqdm(df.iterrows(), desc=\"Aligning audio\", total=df.shape[0]):  \n",
    "    subject = row['subject']\n",
    "    story_name = row['story_name']\n",
    "    task = row['task']  # Assuming that you want to align only listening tasks\n",
    "    audio_filename = os.path.join(audio_dir, f\"{story_name}_{task}_{subject}.wav\")\n",
    "    transcript_filename = os.path.join(transcripts_dir, f\"{story_name}.txt\")\n",
    "    aligned_audio_filename = os.path.join(aligned_audio_dir, f\"{story_name}_{task}_{subject}.wav\")\n",
    "\n",
    "    if task == 'listening' and os.path.isfile(audio_filename) and os.path.isfile(transcript_filename):\n",
    "        # Create necessary directories if they don't exist\n",
    "        os.makedirs(aligned_audio_dir, exist_ok=True)\n",
    "\n",
    "        # Create Aeneas text and audio objects\n",
    "        text_obj = aeneas.TextFileParser(transcript_filename).parse() \n",
    "        audio_obj = aeneas.AudioFileParser(audio_filename).parse()\n",
    "\n",
    "        # Align audio and text using Aeneas\n",
    "        aeneas.SentenceAligner(audio_obj, text_obj).align() \n",
    "\n",
    "        # Extract fragment boundaries\n",
    "        fragments = text_obj.fragments \n",
    "\n",
    "        # Save the new audio file with aligned fragments\n",
    "        with wave.open(aligned_audio_filename, 'wb') as out_wave:\n",
    "            out_wave.setparams(audio_obj.audio_file.params)  # Copy params of original audio\n",
    "            for fragment in fragments:      \n",
    "                fragment_audio = audio_obj.audio_file.get_fragment(fragment.begin, fragment.end)\n",
    "                out_wave.writeframes(fragment_audio)  \n",
    "\n",
    "# ---------------------- Update DataFrame (Optional) ---------------------- #\n",
    "# If you want to add a column to your DataFrame indicating the aligned audio file paths,\n",
    "# you can add the following:\n",
    "\n",
    "df.loc[index, 'aligned_audio_file'] = aligned_audio_filename\n",
    "df.to_csv(\"data/df_text.hdf\", index=False)  # Update the DataFrame\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
