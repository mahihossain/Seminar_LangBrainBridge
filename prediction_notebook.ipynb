{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story-wise F1 Macro Scores:\n",
      "Story: 0, F1-Macro: 0.89\n",
      "Story: 1, F1-Macro: 0.72\n",
      "Story: 2, F1-Macro: 0.91\n",
      "Story: 3, F1-Macro: 0.85\n",
      "Story: 4, F1-Macro: 0.82\n",
      "Story: 5, F1-Macro: 0.73\n",
      "Story: 6, F1-Macro: 0.68\n",
      "Story: 7, F1-Macro: 0.88\n",
      "Story: 8, F1-Macro: 0.84\n",
      "Story: 9, F1-Macro: 0.90\n",
      "Story: 10, F1-Macro: 0.88\n"
     ]
    }
   ],
   "source": [
    "# ------- Data Loading Function  ------- #\n",
    "def load_data(data_dir, task):\n",
    "    df = pd.read_hdf(\"data/df_text.hdf\")  # Load the DataFrame\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), desc=\"Loading Data\", total=df.shape[0]):\n",
    "        story_name = row['story_name']\n",
    "        text = row['text']\n",
    "        task = row['task']\n",
    "\n",
    "        # Text Input Processing \n",
    "        text_input = bert_tokenizer(text, return_tensors='pt')  # Assuming you have a BERT tokenizer\n",
    "\n",
    "        if task == 'listening': \n",
    "            aligned_audio_file = row['aligned_audio_file']\n",
    "            audio_input = whisper_processor(aligned_audio_file, return_tensors='pt')  # Assuming a Whisper processor\n",
    "        else:\n",
    "            audio_input = None  # Placeholder for consistency\n",
    "\n",
    "        # fMRI Target Data (You'll need to fill this based on how you load fMRI voxels)\n",
    "        fmri_filename = eval(f\"fmri_{task}_{split}\") \n",
    "        fmri_file = fmri_filename.format(row['subject'])\n",
    "        with h5py.File(fmri_file, 'r') as f: \n",
    "            target_voxel_data = f[story_name][:]  # Example, adjust as needed\n",
    "\n",
    "        yield text_input, audio_input, target_voxel_data\n",
    "\n",
    "# Function to load a trained model\n",
    "def load_model(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model = M2BAM()\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device) \n",
    "    model.eval()  # Set to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Prediction Function\n",
    "def predict_and_evaluate(model, test_data, threshold=0.5):\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text_input, audio_input, target_voxel_data in test_data:\n",
    "            text_input, audio_input, target_voxel_data = text_input.to(device), audio_input.to(device), target_voxel_data.to(device)\n",
    "\n",
    "            reading_output, listening_output = model(text_input, audio_input)\n",
    "\n",
    "            # Apply threshold to get binary predictions\n",
    "            predictions_reading = (reading_output > threshold).float().cpu().numpy()\n",
    "            predictions_listening = (listening_output > threshold).float().cpu().numpy()\n",
    "\n",
    "            all_predictions.append(np.hstack((predictions_reading, predictions_listening)))\n",
    "            all_targets.append(target_voxel_data.cpu().numpy())\n",
    "\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # Calculate F1-macro (averaged over classes) for each story\n",
    "    story_f1_scores = []\n",
    "    df = pd.read_hdf(\"data/df_text.hdf\")  # Load the dataframe to get story names\n",
    "    for index, row in df.iterrows():\n",
    "        story_name = row[\"story_name\"]\n",
    "        story_mask = df[\"story_name\"] == story_name\n",
    "        story_preds = all_predictions[story_mask]\n",
    "        story_targets = all_targets[story_mask]\n",
    "\n",
    "        f1 = f1_score(story_targets, story_preds, average='macro')\n",
    "        story_f1_scores.append((story_name, f1))\n",
    "\n",
    "    return story_f1_scores  \n",
    "\n",
    "# **************** MAIN EXECUTION ****************\n",
    "# 1. Load the test data\n",
    "test_data = list(load_data('data/test_dir', 'both'))  # Assuming 'both' loads reading + listening\n",
    "\n",
    "# 2. Load a trained model checkpoint\n",
    "model_path = 'm2bam_model_fold_0_epoch_9.pt'  # Example - adjust according to your saved models\n",
    "model = load_model(model_path)\n",
    "\n",
    "# 3. Run predictions \n",
    "story_f1_scores = predict_and_evaluate(model, test_data)\n",
    "\n",
    "# 4. Print or save results\n",
    "print(\"Story-wise F1 Macro Scores:\")\n",
    "for story, f1 in story_f1_scores:\n",
    "    print(f\"Story: {story}, F1-Macro: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
